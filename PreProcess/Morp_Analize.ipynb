{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "b9d3bf71fe82dc7159b853f8f5ac3e2334aa339c3d1653768411f33acf68962a"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# kiwipiepy 모듈\n",
    "```\n",
    "pip install kiwipiepy\n",
    "```\n",
    "jupyter-notebook 단축기\n",
    "* `a` : 위에 셀 추가\n",
    "* `b` : 아래에 셀 추가\n",
    "* `dd` : 셀 삭제\n",
    "* `m` : 문서 셀로 변경\n",
    "* `y` : 코드 셀로 변경"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['것', '수', '이', '나', '사람', '등', '우리', '때', '년', '말', '일', '때문', '그것', '일', '문제', '사회', '중', '씨', '지금', '속', '하나', '집', '월', '데', '자신', '내', '경우', '명', '생각', '시간', '그녀', '앞', '번', '여자', '개', '전', '사실', '점', '정도', '원', '소리']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"한국어불용어100.txt\", 'r', encoding=\"utf-8\")\n",
    "stopword=[]\n",
    "\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    if not line: break\n",
    "    wordlist = line.split('\\t')\n",
    "    if (wordlist[1].startswith('N')):\n",
    "        stopword.append(wordlist[0])\n",
    "\n",
    "print(stopword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reader:\n",
    "    def __init__(self, filePath):\n",
    "        self.file = open(filePath,'r',encoding='UTF-8')\n",
    "    \n",
    "    def read(self, id):\n",
    "        if id == 0: self.file.seek(0)\n",
    "        return self.file.readline()\n",
    "\n",
    "reader = Reader('datas.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['것', '수', '이', '나', '사람', '등', '우리', '때', '년', '말', '일', '때문', '그것', '일', '문제', '사회', '중', '씨', '지금', '속', '하나', '집', '월', '데', '자신', '내', '경우', '명', '생각', '시간', '그녀', '앞', '번', '여자', '개', '전', '사실', '점', '정도', '원', '소리']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import io\n",
    "import re # 정규표현식 패키지\n",
    "from kiwipiepy import Kiwi, Option\n",
    "import tomotopy as tp\n",
    "\n",
    "file = open(\"한국어불용어100.txt\", 'r', encoding=\"utf-8\")\n",
    "stopword=[]\n",
    "\n",
    "while True:\n",
    "    line = file.readline()\n",
    "    if not line: break\n",
    "    wordlist = line.split('\\t')\n",
    "    if (wordlist[1].startswith('N')):\n",
    "        stopword.append(wordlist[0])\n",
    "\n",
    "print(stopword)\n",
    "\n",
    "filename=\"datas.txt\"  #파일 경로\n",
    "file = open(filename, 'r', encoding=\"UTF-8\")\n",
    "kiwi=Kiwi()\n",
    "kiwi.extract_add_words(reader.read)\n",
    "kiwi.prepare()\n",
    "stopwords = set(stopword)\n",
    "\n",
    "\n",
    "def tokenize(sent): # 파일의 라인을 분석할 tokenize 함수\n",
    "    res, score = kiwi.analyze(sent)[0] # 첫번째 결과를 사용한다, 분석할때 나오는 결과에서 단어만 추출\n",
    "    return [word\n",
    "            for word, tag, _, _ in res\n",
    "            if tag.startswith('N') and word not in stopwords] #불용어사전 적용\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Document #0 has been loaded\n",
      "Document #10 has been loaded\n",
      "Document #20 has been loaded\n",
      "Document #30 has been loaded\n",
      "Document #40 has been loaded\n",
      "Document #50 has been loaded\n",
      "Document #60 has been loaded\n",
      "Document #70 has been loaded\n",
      "Document #80 has been loaded\n",
      "Document #90 has been loaded\n",
      "Document #100 has been loaded\n",
      "Document #110 has been loaded\n",
      "Document #120 has been loaded\n",
      "Document #130 has been loaded\n",
      "Document #140 has been loaded\n",
      "Document #150 has been loaded\n",
      "Document #160 has been loaded\n",
      "Document #170 has been loaded\n",
      "Document #180 has been loaded\n",
      "Document #190 has been loaded\n",
      "Document #200 has been loaded\n",
      "Document #210 has been loaded\n",
      "Document #220 has been loaded\n",
      "Document #230 has been loaded\n",
      "Document #240 has been loaded\n",
      "Document #250 has been loaded\n",
      "Document #260 has been loaded\n",
      "Document #270 has been loaded\n",
      "Document #280 has been loaded\n",
      "Document #290 has been loaded\n",
      "Document #300 has been loaded\n",
      "Document #310 has been loaded\n",
      "Document #320 has been loaded\n",
      "Document #330 has been loaded\n",
      "Document #340 has been loaded\n",
      "Document #350 has been loaded\n",
      "Document #360 has been loaded\n",
      "Document #370 has been loaded\n",
      "Document #380 has been loaded\n",
      "Document #390 has been loaded\n",
      "Document #400 has been loaded\n",
      "Document #410 has been loaded\n",
      "Document #420 has been loaded\n",
      "Document #430 has been loaded\n",
      "Document #440 has been loaded\n",
      "Document #450 has been loaded\n",
      "Document #460 has been loaded\n",
      "Document #470 has been loaded\n",
      "Document #480 has been loaded\n",
      "Document #490 has been loaded\n",
      "Document #500 has been loaded\n",
      "Document #510 has been loaded\n",
      "Document #520 has been loaded\n",
      "Document #530 has been loaded\n",
      "Document #540 has been loaded\n",
      "Document #550 has been loaded\n",
      "Document #560 has been loaded\n",
      "Document #570 has been loaded\n",
      "Document #580 has been loaded\n",
      "Document #590 has been loaded\n",
      "Document #600 has been loaded\n",
      "Document #610 has been loaded\n",
      "Document #620 has been loaded\n",
      "Document #630 has been loaded\n",
      "Document #640 has been loaded\n",
      "Document #650 has been loaded\n",
      "Document #660 has been loaded\n",
      "Document #670 has been loaded\n",
      "Document #680 has been loaded\n",
      "Document #690 has been loaded\n",
      "Document #700 has been loaded\n",
      "Document #710 has been loaded\n",
      "Document #720 has been loaded\n",
      "Document #730 has been loaded\n",
      "Document #740 has been loaded\n",
      "Document #750 has been loaded\n",
      "Document #760 has been loaded\n",
      "Document #770 has been loaded\n",
      "Document #780 has been loaded\n",
      "Document #790 has been loaded\n",
      "Document #800 has been loaded\n",
      "Document #810 has been loaded\n",
      "Document #820 has been loaded\n",
      "Document #830 has been loaded\n",
      "Document #840 has been loaded\n",
      "Document #850 has been loaded\n",
      "Document #860 has been loaded\n",
      "Document #870 has been loaded\n",
      "Document #880 has been loaded\n",
      "Document #890 has been loaded\n",
      "Document #900 has been loaded\n",
      "Document #910 has been loaded\n",
      "Document #920 has been loaded\n",
      "Document #930 has been loaded\n",
      "Document #940 has been loaded\n",
      "Document #950 has been loaded\n",
      "Document #960 has been loaded\n",
      "Document #970 has been loaded\n",
      "Document #980 has been loaded\n",
      "Document #990 has been loaded\n",
      "Document #1000 has been loaded\n",
      "Document #1010 has been loaded\n",
      "Document #1020 has been loaded\n",
      "Document #1030 has been loaded\n",
      "Document #1040 has been loaded\n",
      "Document #1050 has been loaded\n",
      "Document #1060 has been loaded\n",
      "Document #1070 has been loaded\n",
      "Document #1080 has been loaded\n",
      "Document #1090 has been loaded\n",
      "Document #1100 has been loaded\n",
      "Document #1110 has been loaded\n",
      "Document #1120 has been loaded\n",
      "Document #1130 has been loaded\n",
      "Document #1140 has been loaded\n",
      "Document #1150 has been loaded\n",
      "Document #1160 has been loaded\n",
      "Document #1170 has been loaded\n",
      "Document #1180 has been loaded\n",
      "Document #1190 has been loaded\n",
      "Document #1200 has been loaded\n",
      "Document #1210 has been loaded\n",
      "Document #1220 has been loaded\n",
      "Document #1230 has been loaded\n",
      "Document #1240 has been loaded\n",
      "Document #1250 has been loaded\n",
      "Document #1260 has been loaded\n",
      "Document #1270 has been loaded\n",
      "Document #1280 has been loaded\n",
      "Document #1290 has been loaded\n",
      "Document #1300 has been loaded\n",
      "Document #1310 has been loaded\n",
      "Document #1320 has been loaded\n",
      "Document #1330 has been loaded\n",
      "Document #1340 has been loaded\n",
      "Document #1350 has been loaded\n",
      "Document #1360 has been loaded\n",
      "Document #1370 has been loaded\n",
      "Document #1380 has been loaded\n",
      "Document #1390 has been loaded\n",
      "Document #1400 has been loaded\n",
      "Document #1410 has been loaded\n",
      "Document #1420 has been loaded\n",
      "Document #1430 has been loaded\n",
      "Document #1440 has been loaded\n",
      "Document #1450 has been loaded\n",
      "Document #1460 has been loaded\n",
      "Document #1470 has been loaded\n",
      "Document #1480 has been loaded\n",
      "Document #1490 has been loaded\n",
      "Document #1500 has been loaded\n",
      "Document #1510 has been loaded\n",
      "Document #1520 has been loaded\n",
      "Document #1530 has been loaded\n",
      "Document #1540 has been loaded\n",
      "Document #1550 has been loaded\n",
      "Document #1560 has been loaded\n",
      "Document #1570 has been loaded\n",
      "Document #1580 has been loaded\n",
      "Document #1590 has been loaded\n",
      "Document #1600 has been loaded\n",
      "Document #1610 has been loaded\n",
      "Document #1620 has been loaded\n",
      "Document #1630 has been loaded\n",
      "Document #1640 has been loaded\n",
      "Document #1650 has been loaded\n",
      "Document #1660 has been loaded\n",
      "Document #1670 has been loaded\n",
      "Document #1680 has been loaded\n",
      "Document #1690 has been loaded\n",
      "Document #1700 has been loaded\n",
      "Document #1710 has been loaded\n",
      "Document #1720 has been loaded\n",
      "Document #1730 has been loaded\n",
      "Document #1740 has been loaded\n",
      "Document #1750 has been loaded\n",
      "Document #1760 has been loaded\n",
      "Document #1770 has been loaded\n",
      "Document #1780 has been loaded\n",
      "Document #1790 has been loaded\n",
      "Document #1800 has been loaded\n",
      "Document #1810 has been loaded\n",
      "Document #1820 has been loaded\n",
      "Document #1830 has been loaded\n",
      "Document #1840 has been loaded\n",
      "Document #1850 has been loaded\n",
      "Document #1860 has been loaded\n",
      "Document #1870 has been loaded\n",
      "Document #1880 has been loaded\n",
      "Document #1890 has been loaded\n",
      "Document #1900 has been loaded\n",
      "Document #1910 has been loaded\n",
      "Document #1920 has been loaded\n",
      "Document #1930 has been loaded\n",
      "Document #1940 has been loaded\n",
      "Document #1950 has been loaded\n",
      "Document #1960 has been loaded\n",
      "Document #1970 has been loaded\n",
      "Document #1980 has been loaded\n",
      "Document #1990 has been loaded\n",
      "Document #2000 has been loaded\n",
      "Document #2010 has been loaded\n",
      "Document #2020 has been loaded\n",
      "Document #2030 has been loaded\n",
      "Document #2040 has been loaded\n",
      "Document #2050 has been loaded\n",
      "Document #2060 has been loaded\n",
      "Document #2070 has been loaded\n",
      "Document #2080 has been loaded\n",
      "Document #2090 has been loaded\n",
      "Document #2100 has been loaded\n",
      "Document #2110 has been loaded\n",
      "Document #2120 has been loaded\n",
      "Document #2130 has been loaded\n",
      "Document #2140 has been loaded\n",
      "Document #2150 has been loaded\n",
      "Document #2160 has been loaded\n",
      "Document #2170 has been loaded\n",
      "Document #2180 has been loaded\n",
      "Document #2190 has been loaded\n",
      "Document #2200 has been loaded\n",
      "Document #2210 has been loaded\n",
      "Document #2220 has been loaded\n",
      "Document #2230 has been loaded\n",
      "Document #2240 has been loaded\n",
      "Document #2250 has been loaded\n",
      "Document #2260 has been loaded\n",
      "Document #2270 has been loaded\n",
      "Document #2280 has been loaded\n",
      "Document #2290 has been loaded\n",
      "Document #2300 has been loaded\n",
      "Document #2310 has been loaded\n",
      "Document #2320 has been loaded\n",
      "Document #2330 has been loaded\n",
      "Document #2340 has been loaded\n",
      "Document #2350 has been loaded\n",
      "Document #2360 has been loaded\n",
      "Document #2370 has been loaded\n",
      "Document #2380 has been loaded\n",
      "Document #2390 has been loaded\n",
      "Document #2400 has been loaded\n",
      "Document #2410 has been loaded\n",
      "Document #2420 has been loaded\n",
      "Document #2430 has been loaded\n",
      "Document #2440 has been loaded\n",
      "Document #2450 has been loaded\n",
      "Document #2460 has been loaded\n",
      "Document #2470 has been loaded\n",
      "Document #2480 has been loaded\n",
      "Document #2490 has been loaded\n",
      "Document #2500 has been loaded\n",
      "Document #2510 has been loaded\n",
      "Document #2520 has been loaded\n",
      "Document #2530 has been loaded\n",
      "Document #2540 has been loaded\n",
      "Document #2550 has been loaded\n",
      "Document #2560 has been loaded\n",
      "Document #2570 has been loaded\n",
      "Document #2580 has been loaded\n",
      "Document #2590 has been loaded\n",
      "Document #2600 has been loaded\n",
      "Document #2610 has been loaded\n",
      "Document #2620 has been loaded\n",
      "Document #2630 has been loaded\n",
      "Document #2640 has been loaded\n",
      "Document #2650 has been loaded\n",
      "Document #2660 has been loaded\n",
      "Document #2670 has been loaded\n",
      "Document #2680 has been loaded\n",
      "Document #2690 has been loaded\n",
      "Document #2700 has been loaded\n",
      "Document #2710 has been loaded\n",
      "Document #2720 has been loaded\n",
      "Document #2730 has been loaded\n",
      "Document #2740 has been loaded\n",
      "Document #2750 has been loaded\n",
      "Document #2760 has been loaded\n",
      "Document #2770 has been loaded\n",
      "Document #2780 has been loaded\n",
      "Document #2790 has been loaded\n",
      "Document #2800 has been loaded\n",
      "Document #2810 has been loaded\n",
      "Document #2820 has been loaded\n",
      "Document #2830 has been loaded\n",
      "Document #2840 has been loaded\n",
      "Document #2850 has been loaded\n",
      "Document #2860 has been loaded\n",
      "Document #2870 has been loaded\n",
      "Document #2880 has been loaded\n",
      "Document #2890 has been loaded\n",
      "Document #2900 has been loaded\n",
      "Document #2910 has been loaded\n",
      "Document #2920 has been loaded\n",
      "Total docs: 703\n",
      "Total words: 180167\n",
      "Vocab size: 2103\n",
      "Iteration 0\tLL per word: -21.623035548862987\n",
      "Iteration 20\tLL per word: -16.60596913806074\n",
      "Iteration 40\tLL per word: -16.375594354417498\n",
      "Iteration 60\tLL per word: -16.287445209284677\n",
      "Iteration 80\tLL per word: -16.229824664897542\n",
      "Iteration 100\tLL per word: -16.19028979524256\n",
      "Iteration 120\tLL per word: -16.156891453151147\n",
      "Iteration 140\tLL per word: -16.124713203738416\n",
      "Iteration 160\tLL per word: -16.11410740117239\n",
      "Iteration 180\tLL per word: -16.079820561120812\n",
      "Iteration 200\tLL per word: -16.056315058490682\n",
      "Iteration 220\tLL per word: -16.036836846374385\n",
      "Iteration 240\tLL per word: -16.028073422532188\n",
      "Iteration 260\tLL per word: -16.007252034128463\n",
      "Iteration 280\tLL per word: -15.995621070935226\n",
      "Iteration 300\tLL per word: -15.976601287484716\n",
      "Iteration 320\tLL per word: -15.96615499248331\n",
      "Iteration 340\tLL per word: -15.954257480636898\n",
      "Iteration 360\tLL per word: -15.958510419223693\n",
      "Iteration 380\tLL per word: -15.94359461703496\n",
      "Iteration 400\tLL per word: -15.94616881844867\n",
      "Iteration 420\tLL per word: -15.942272119865882\n",
      "Iteration 440\tLL per word: -15.938199574496059\n",
      "Iteration 460\tLL per word: -15.931622846046457\n",
      "Iteration 480\tLL per word: -15.92979129000432\n",
      "Iteration 500\tLL per word: -15.925467325321913\n",
      "Iteration 520\tLL per word: -15.922433062529201\n",
      "Iteration 540\tLL per word: -15.927476324637311\n",
      "Iteration 560\tLL per word: -15.91943896235278\n",
      "Iteration 580\tLL per word: -15.921688617548407\n",
      "Iteration 600\tLL per word: -15.913197900114522\n",
      "Iteration 620\tLL per word: -15.91520520724372\n",
      "Iteration 640\tLL per word: -15.921963709047413\n",
      "Iteration 660\tLL per word: -15.920399218429635\n",
      "Iteration 680\tLL per word: -15.913879470539355\n",
      "Iteration 700\tLL per word: -15.911458349168456\n",
      "Iteration 720\tLL per word: -15.906891629399496\n",
      "Iteration 740\tLL per word: -15.908518896206315\n",
      "Iteration 760\tLL per word: -15.906911547765626\n",
      "Iteration 780\tLL per word: -15.900992562463989\n",
      "Iteration 800\tLL per word: -15.900052473610854\n",
      "Iteration 820\tLL per word: -15.90113562935416\n",
      "Iteration 840\tLL per word: -15.902898714136569\n",
      "Iteration 860\tLL per word: -15.89793068522501\n",
      "Iteration 880\tLL per word: -15.902557748445524\n",
      "Iteration 900\tLL per word: -15.899993885819658\n",
      "Iteration 920\tLL per word: -15.897943199097972\n",
      "Iteration 940\tLL per word: -15.900619008655614\n",
      "Iteration 960\tLL per word: -15.902990897483336\n",
      "Iteration 980\tLL per word: -15.90466249204889\n",
      "Topic #0\t태풍, 하이선, 기상청, 시, 호\n",
      "Topic #1\t투자, 펀드, 시장, 추천, 나훈아\n",
      "Topic #2\t확진자, 집회, 코로나19, 서울, 환자\n",
      "Topic #3\t의원, 아베, 총리, 대표, 국회\n",
      "Topic #4\t장관, 휴가, 추, 아들, 병가\n",
      "Topic #5\tA씨, 경찰, 혐의, 사건, 시위\n",
      "Topic #6\t중국, 미국, 트럼프, 대통령, 네이버\n",
      "Topic #7\t채용, 기업, 북한, 교수, 김\n",
      "Topic #8\t지급, 지원, 지원금, 지사, 차\n",
      "Topic #9\t의사, 합의, 의협, 의대, 의료\n"
     ]
    }
   ],
   "source": [
    "import tomotopy as tp\n",
    "\n",
    "model = tp.LDAModel(k=10, alpha=0.1, eta=0.01, min_cf=20,min_df=10, tw=tp.TermWeight.PMI)\n",
    "#LDA 모델을 적용해서 토픽 추출, k는 topic 개수\n",
    "#alpha는 문헌-토픽 디리클레 분포의 하이퍼 파라미터\n",
    "#eta는 토픽-단어 디리클레 분포의 하이퍼 파라미터 두개다 상수인듯하다\n",
    "#min_cf는 단어의 최소 장서 빈도수, 전체 문헌내 출현빈도\n",
    "#min_df는 단어의 최서 문헌 빈도수, 출현한 문헌 숫자수 의미\n",
    "#tw는 용어 가중치 기법으로, ONE, IDF, PMI를 사용가능, ONE 보다는 PMI나 IDF 둘중 하나 사용 \n",
    "\n",
    "for i, line in enumerate(open(filename, encoding='utf-8')): #해당 경로의 파일을 받아와 한 라인씩 model에 추가\n",
    "    model.add_doc(tokenize(line)) #추출하고 모델안의 문헌을 넣는다. 즉, 학습과정에 쓰일 문헌을 생성\n",
    "    if i % 10 == 0: print('Document #{} has been loaded'.format(i))\n",
    " \n",
    "model.train(0) #학습 초기화\n",
    "\n",
    "print('Total docs:', len(model.docs)) #문헌들\n",
    "print('Total words:', model.num_words) #전체단어개수\n",
    "print('Vocab size:', model.num_vocabs) #전체 어휘개수\n",
    " \n",
    " \n",
    "for i in range(0,1000,20):\n",
    "    print('Iteration {}\\tLL per word: {}'.format(i, model.ll_per_word))\n",
    "    model.train(20) #문헌 학습, 안에 숫자는 깁스 샘플링의 반복횟수\n",
    "\t\t#이때 기본값으로 시스템내 가용한 모든 스레드의 개수사용, 그리고 병렬화 방법을 찾아서 실행시켜준다\n",
    "  \n",
    "for i in range(model.k): #k는 토픽의 개수\n",
    "    res = model.get_topic_words(i, top_n=5) #하위 토픽 i에 해당하는 top_n개의 단어 반환\n",
    "    print('Topic #{}'.format(i), end='\\t')\n",
    "    print(', '.join(w for w, p in res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}