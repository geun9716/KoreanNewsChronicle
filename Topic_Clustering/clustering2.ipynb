{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('C:/Users/geun/KoreanNewsChronicle/Topic_Clustering/201901.csv',encoding='utf-8')\n",
    "\n",
    "# 결측지 행 제거 후 topics에 있는 것을 추출\n",
    "s = df.dropna()\n",
    "tmp_index=[]\n",
    "\n",
    "for index, row in s.iterrows():\n",
    "    tmp = row['topics'].split(',')\n",
    "    if len(tmp) < 2:\n",
    "        tmp_index.append(index)\n",
    "\n",
    "s = s.drop(tmp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_topic = s['topics'].tolist()\n",
    "\n",
    "# # CountVectrizer로 토큰화\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(news_topic)\n",
    "\n",
    "X = normalize(X)\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "\n",
    "m = DBSCAN(eps=0.6, min_samples = 5)\n",
    "\n",
    "m.fit(X)\n",
    "\n",
    "labels = m.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{-1: 23002, 1: 193, 11: 18, 12: 18, 33: 14, 5: 13, 41: 11, 14: 10, 16: 9, 28: 9, 18: 8, 27: 8, 37: 8, 0: 7, 8: 7, 35: 7, 4: 6, 10: 6, 23: 6, 30: 6, 24: 6, 26: 6, 3: 5, 2: 5, 6: 5, 7: 5, 9: 5, 20: 5, 15: 5, 17: 5, 19: 5, 22: 5, 31: 5, 25: 5, 29: 5, 32: 5, 34: 5, 36: 5, 38: 5, 39: 5, 40: 5, 43: 5, 42: 5, 21: 4, 13: 3}\n"
     ]
    }
   ],
   "source": [
    "s['labels'] = labels\n",
    "\n",
    "hot_topic_index = Counter(s['labels']).most_common()\n",
    "hot_topic = dict(hot_topic_index)\n",
    "\n",
    "print(hot_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = []\n",
    "for row in s['labels']:\n",
    "    index.append(hot_topic[row])\n",
    "\n",
    "s['cnt'] = index\n",
    "s.sort_values(by='labels', ascending=False).to_csv('201901_cluster_DBSCAN_10.csv', index=False, header=True,encoding=\"utf-8-sig\")"
   ]
  }
 ]
}