{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "2db524e06e9f5f4ffedc911c917cb75e12dbc923643829bf417064a77eb14d37"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import math\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv('C:/Users/geun/KoreanNewsChronicle/Topic_Abstract/Data/201912.csv',encoding='utf-8')\n",
    "\n",
    "# 결측지 행 제거 후 topics에 있는 것을 추출\n",
    "s = df.dropna()\n",
    "tmp_index=[]\n",
    "\n",
    "for index, row in s.iterrows():\n",
    "    tmp = row['topics'].split(',')\n",
    "    if len(tmp) < 2:\n",
    "        tmp_index.append(index)\n",
    "\n",
    "s = s.drop(tmp_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "news_topic = s['topics'].tolist()\n",
    "\n",
    "# # CountVectrizer로 토큰화\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(news_topic)\n",
    "\n",
    "X = normalize(X)\n",
    "\n",
    "neigh = NearestNeighbors(n_neighbors=2)\n",
    "nbrs = neigh.fit(X)\n",
    "distances, indices = nbrs.kneighbors(X)\n",
    "\n",
    "\n",
    "m = DBSCAN(eps=0.6, min_samples = 5)\n",
    "\n",
    "m.fit(X)\n",
    "\n",
    "labels = m.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{-1: 25408, 13: 88, 41: 45, 20: 40, 14: 36, 39: 27, 33: 21, 24: 16, 12: 14, 51: 14, 35: 12, 17: 11, 32: 10, 2: 9, 31: 9, 48: 9, 53: 9, 62: 9, 67: 9, 69: 9, 1: 8, 8: 8, 9: 8, 15: 8, 61: 8, 22: 8, 80: 8, 50: 8, 55: 8, 59: 8, 68: 8, 75: 8, 4: 7, 5: 7, 7: 7, 23: 7, 30: 7, 25: 7, 28: 7, 34: 7, 52: 7, 63: 7, 65: 7, 72: 7, 0: 6, 10: 6, 36: 6, 16: 6, 26: 6, 29: 6, 37: 6, 38: 6, 43: 6, 44: 6, 46: 6, 54: 6, 56: 6, 78: 6, 76: 6, 79: 6, 49: 5, 3: 5, 6: 5, 11: 5, 21: 5, 18: 5, 19: 5, 27: 5, 47: 5, 40: 5, 42: 5, 64: 5, 45: 5, 57: 5, 60: 5, 58: 5, 66: 5, 70: 5, 81: 5, 71: 5, 73: 5, 74: 5, 77: 5}\n"
     ]
    }
   ],
   "source": [
    "s['labels'] = labels\n",
    "\n",
    "hot_topic_index = Counter(s['labels']).most_common()\n",
    "hot_topic = dict(hot_topic_index)\n",
    "\n",
    "print(hot_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = []\n",
    "for index, row in s['labels'].iteritems():\n",
    "    if row == -1:\n",
    "        s = s.drop(index)\n",
    "    else:\n",
    "        count.append(hot_topic[row])\n",
    "\n",
    "s['cnt'] = count\n",
    "s.sort_values(by='labels', ascending=False).to_csv('./Data/201912_cluster_DBSCAN_10.csv', index=False, header=True,encoding=\"utf-8-sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}