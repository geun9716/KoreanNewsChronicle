{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from kiwipiepy import Kiwi\n",
    "from kss import split_sentences\n",
    "from collections import Counter\n",
    "import pprint as pp\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"C:/Users/ghdtk/OneDrive/Desktop/VSCode/Python/KoreanNewsChronicle/Data/2019/2019 북미정상회담.txt\", \"r\", encoding = 'utf-8')\n",
    "content = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "kiwi = Kiwi()\n",
    "kiwi.load_user_dictionary('../PreProcess/new_wordlist.txt')\n",
    "kiwi.prepare()\n",
    "\n",
    "stopword = []\n",
    "def rm_stopword(stopword_file): \n",
    "    files = open(stopword_file, 'r', encoding=\"utf-8-sig\")\n",
    "    while True: #불용어 리스트 생성\n",
    "        line = files.readline()\n",
    "        if not line: break\n",
    "        wordlist = line.split('\\t')\n",
    "        if wordlist[1].startswith('N'):\n",
    "            stopword.append(wordlist[0])\n",
    "    stopwords = set(stopword)\n",
    "    files.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_stopword('../PreProcess/한국어불용어100.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rm_stopword('../PreProcess/한국어불용어100.txt')\n",
    "docs = []\n",
    "merge_token = []\n",
    "bi_gram = {}\n",
    "LDA_Topics = []\n",
    "i = 0\n",
    "for news in open('C:/Users/ghdtk/OneDrive/Desktop/VSCode/Python/KoreanNewsChronicle/Data/2019/2019 북미정상회담.txt', encoding='utf-8'):\n",
    "    doc = []\n",
    "    context = []\n",
    "    com = []\n",
    "    lines = split_sentences(news)\n",
    "\n",
    "    #형태소 분석\n",
    "    for res in kiwi.analyze(lines):\n",
    "        content = [word.strip() for word, tag, _, _ in res[0][0] if tag.startswith('N') and word not in stopword] #불용어사전 적용\n",
    "#         context += content\n",
    "        doc.append(content)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for Nouns in doc:\n",
    "    Nouns = str(Nouns)\n",
    "    Nouns = Nouns.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "    corpus.append(\" \".join(Nouns.split(', ')))\n",
    "c = \" \".join(corpus)\n",
    "corpus2 = []\n",
    "corpus2.append(c)\n",
    "corpus = corpus2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "sp_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "word2id = defaultdict(lambda : 0)\n",
    "for idx, feature in enumerate(vectorizer.get_feature_names()):\n",
    "    word2id[feature] = idx\n",
    "\n",
    "mylist = []\n",
    "for i, sent in enumerate(corpus):\n",
    "#     print('====== document[%d] ======' % i)\n",
    "    mylist.append([(token, sp_matrix[i, word2id[token]]) for token in sent.split()])\n",
    "#     print( [ (token, sp_matrix[i, word2id[token]]) for token in sent.split() ] )\n",
    "    if i % 10000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for m in mylist:\n",
    "    words = []\n",
    "    values = []\n",
    "    for noun in m:\n",
    "        words.append(noun[0])\n",
    "        values.append(noun[1])\n",
    "    doc = pd.DataFrame({\"word\":words, \"value\":values})\n",
    "    doc = doc.drop_duplicates(['word'])\n",
    "    doc = doc.sort_values(by = 'value', ascending = False)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for doc in docs:\n",
    "    df2 = pd.DataFrame(doc)\n",
    "    topic = []\n",
    "    for i in range(len(df2)):\n",
    "        topic.append(df2.iloc[i]['word'])\n",
    "        if(i == 9):\n",
    "            break\n",
    "    topics.append(', '.join(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oasis_topic = topics\n",
    "oasis_topic = [\"회담, 위원장, 영변, 조건, 결렬, 하노이, 김정은, 대통령, 정상, 미국\",\n",
    "              \"진화, 산불, 피해, 인근, 출동, 오후, 강원도, 토성면, 원암리, 강풍\",\n",
    "              \"구조, 수색, 헝가리인, 크루즈, 바이킹, 승무원, 헝가리, 정부, 외교부, 강경화\",\n",
    "              \"회담, 대통령, 트럼프, 정상, 중요, 실무, 도널드, 미국, 김정은, 합의\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['베트남', '하노이', '도널드 트럼프 미국', '대통령', '김정은 북한 국무', '위원회', '위원장', '간', '정상회담', '개최']\n['제1차 정상회담', '이후', '회담']\n['도널드', '트럼프 대통령', '김정은', '위원장', '하노이', '소피', '텔', '레전드', '메트로', '폴', '호텔']\n['회담 2일째', '업무', '오찬', '취소', '회담 결렬', '선언']\n['최종', '합의', '북한', '영변', '핵', '조건', '한 대북제재', '완전', '해제', '제안', '미국', '영변', '외', '지역', '핵', '시설', '핵', '조건', '제시']\n['선언문', '준비', '의견', '상충', '채택', '결렬']\n"
     ]
    }
   ],
   "source": [
    "from kss import split_sentences\n",
    "\n",
    "lines='2019년 2월 27일부터 28일까지 베트남 하노이에서 도널드 트럼프 미국 대통령과 김정은 북한 국무위원회 위원장 간의 정상회담이 개최되었다. 제1차 정상회담 이후로 260일 만에 열린 회담이다. 도널드 트럼프 대통령과 김정은 위원장은 하노이 소피텔 레전드 메트로폴 호텔에서 만났다. 그러나 회담 2일째의 업무 오찬이 돌연 취소됐고, 곧이어 뜻밖에도 회담 결렬이 선언되었다. 최종합의에서 북한은 영변 비핵화를 조건으로 한 대북제재 완전 해제를 제안하였으나, 미국은 영변 외 지역의 다른 핵시설까지도 완전히 비핵화할 것을 조건으로 제시하였다. 선언문은 준비되어 있었으나, 두 의견이 상충하면서 채택이 결렬되었다.'\n",
    "lines_split=split_sentences(lines)\n",
    "\n",
    "for res in kiwi.analyze(lines_split):\n",
    "    #content = [word.strip() for word, tag, _, _ in res[0][0] if tag.startswith('N') and word not in stopword] #불용어사전 적용\n",
    "    content=[word.strip() for word, tag, _, _ in res[0][0] if tag.startswith('N') and word not in stopword]\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv = pd.read_csv(\"../Data/2019 북미정상회담-데이터10.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    김정은 국무위원장은 2019년 신년사에서 “미국 대통령과 마주 앉을 준비가 되어 있...\n1    27~28일 베트남 하노이에서 열리는 2차 북미정상회담을 앞두고 한국의 역할과 노력...\n2    문재인 대통령은 2월 28일 18시50분부터 25분 동안 도널드 트럼프 미국 대통령...\n3    한미연합훈련인 키리졸브(KR:Key Resolve) 연습과 독수리훈련(FE:Foal...\n4    키리졸브연습은 한미 연합군사령부가 연합사 '작전계획 5027' 등을 적용해 컴퓨터 ...\n5    일본의 주요 언론 매체들은 28일 베트남 하노이에서 열린 2차 북미 정상회담이 '하...\n6    제2차 북미 정상회담이 합의에 이르지 못하고 결렬됐지만, 북한은 1일 이를 전혀 언...\n7    도널드 트럼프 미국 대통령이 연두교서에서 제2차 북미 정상회담 날짜를 확정하면서 전...\n8    김정은 북한 국무위원장이 베트남 하노이에서 열리는 2차 북미 정상회담에 참석하기 위...\n9    김정은 북한 국무위원장에게 이번 2차 북미 정상회담은 그 결과에 따라 북한이 목표로...\nName: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "text=csv['text']\n",
    "print(text)\n",
    "\n",
    "with open('News_Contents.txt','w',encoding='utf-8-sig') as file:\n",
    "    for item in text:\n",
    "        file.write(\"%s\\n\" % item.replace(\"\\n\",\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "merge_token = []\n",
    "bi_gram = {}\n",
    "LDA_Topics = []\n",
    "i = 0\n",
    "for news in open('News_Contents.txt', encoding='utf-8-sig'):\n",
    "    doc = []\n",
    "    context = []\n",
    "    com = []\n",
    "    lines = split_sentences(news)\n",
    "\n",
    "    #형태소 분석\n",
    "    for res in kiwi.analyze(lines):\n",
    "        content = [word.strip() for word, tag, _, _ in res[0][0] if tag.startswith('N') and word not in stopword] #불용어사전 적용\n",
    "#         context += content\n",
    "        doc.append(content)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for doc in docs:\n",
    "    s = \"\"\n",
    "    for Nouns in doc:\n",
    "        Nouns = str(Nouns)\n",
    "        Nouns = Nouns.replace(\"[\", \"\").replace(\"]\", \"\").replace(\"'\", \"\")\n",
    "        s = s + \" \".join(Nouns.split(', '))\n",
    "    corpus.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['김정은 국무 위원장 년 신년사 미국 대통령 준비 국제 사회 환영 결과 노력 것뒤 김영철 당 부위원장 워싱턴 방문 트럼프 대통령 김 위원장 친서 전달차 북미 정상회담 월 일 베트남 하노이 발표이 미국 북한 정상 년 월 일 싱가포르 역사 만남 지 일 만 일김영철 당 부위원장 백악관 트럼프 대통령 한반도 평화 체제 구축 이후 주한 미군 철수 요구 김정은 위원장 입장 공식 전달이 년 월 김용순 당 국제 부장 아널드 캔 터 미 국무부 차관 통일 뒤 지역 세력 균형 안보 주한미군 주둔 필요 입장 전달한 이래 북한 측 미국 전달한 번 발언대 북 제재 완화 협상 카드 북미 간 협의 내용 폼페이오 국무 장관 비건 대표 발언 수비건 대표 월 일 스탠퍼드 대학 연설 전쟁 북한 침공 것 북한 정권 붕괴 시도 것 점 히월 일 문희상 국회 의장 자리 북한 개 이상 문제 논의 싱가포르 공동 성명 이행 협력 것 말폼페이오 국무 장관 월 일 미 CBS 인터뷰 대 북 제재 완화 대가 결과 것 목표 대 북 제재 완화 처음 협상 카드 제시월 일 미 폭스뉴스 인터뷰 한국 전쟁 공식 종식 얘기 핵 한반도 안보 메커니즘 평화 메커니즘 창설 얘기이번 차 북미 정상회담 1차 회담 때 진전 핵 합의문 도출 것 기대미국 협상 초기 일괄 타결 일괄 조치 접근법 부분 단계 접근 수용 선 핵 후 상응조치 입장 견지반면 북한 단계 동시 행동 조치 접근법 일관 주장월 일 비건 대북 정책 특별대표 스탠퍼드 대학 연설 동시 병행 원칙 제시 측 접근법싱가포르 개 항 바탕 개 항 협의 월 일 평양 방문 비건 특별대표 김혁철 대표 협의 차 북미 정상회담 한 주 본격 협상 합의문 조율 것비건 대표 싱가포르 공동 성명 개 항 기초 개 항목 협의 한 것 때 이번 하노이 공동 성명 핵 상응조치 항목 포괄 합의 대한 기대감 수논의 수준 때 이번 회담 한반도 비핵화 상응조치 과정 이행 계획 포함한 일괄 타결 빅딜 것핵 위협 본질 과거 핵 미래 핵 핵 포함 합의 스몰 디 국내외 반발 가능빅딜 실패한 회담 절반 성공 회담 평가 것 스몰딜 머문 것 성공한 회담 평가 수차 북미 정상회담 제약 현실 반영 한반도 완전한 비핵화 비전 수 성공한 회담 어디 합의 도출성공한 회담 방식 최종 검증 비핵화 위한 길목 확보언급 비핵화 핵심 과거 핵 처리 점불신 골 미국 북한 과거 핵 길목 합의 회담 성패 기준영변 핵 시설 폐기 검증 등 예상 북한 주장 단계 동시 행동 접근법 미국 제시한 동시 병행 접근법 결합 이번 차 북미 정상회담 접점 수 것여기 과거 핵 길목 포괄 합의 부분 타결 성공 수 것완전한 비핵화 길목 비건 특별대표 스탠퍼드 대학 연설 바그 포괄 신고 시점 포함한 실무협상 로드맵 히 것 현신 방안 제시지금 협의 제시 것 때 이번 합의문 싱가포르 공동 성명 개 항 구체화한 내용 것 여기 하노이 공동 성명 한반도 핵 부분 예상 이미 파괴 풍계 리 핵실험 장 전문가 검증 전문가 입회 아래 동창리 해체 이행 계획 상응조치 전제 한 영변 핵 시설 폐기 검증 세부 이행 계획 합의 포괄 신고 시점 포함한 실무협상 로드맵 관한 약속 등 가능국제 사회 차 북미 정상회담 이목 집중이번 정상회담 완전한 비핵화 위한 일괄 타결 포괄 합의 과거 핵 포함한 부분타결 한반도 비핵화 평화 의미 진전 가능 것이번 정상회담 성패 평화 한반도 번영 북한 미래 결정 점 때 김정은 위원장 과감한 결단 필요',\n",
       " '일 베트남 하노이 차 북미 정상회담 한국 역할 노력 조명 기고문 미국 워싱턴 타임즈조셉 디트라 6자회담 미국 측 차석 대표 일 신문 게재 한국 대북 외교 노력 제목 기고문 차 북미 정상회담 성공 걸림돌 한국 조용한 사전 작업 인상 환영할만한 것 평가그 청와대 차 북미 정상회담 아무것 방해 요소 작업 북미 정상회담 부정 영향 수 남북 간 군사 충돌 신뢰 구축 합의 발표 과거 논란 서해 관련 북한 재래식 군사 관련 합의 협상 데 성공 언급철수 등 그간 남북 합의 내용 이행 상황 설명이 남북 신뢰 구축 조치 고무 이 완전한 비핵화 대한 김정은 위원장 의지 것 희망 기대그 2차 정상회담 미국 한국 생각 완전한 핵 완전 검증 가능 가역 북한 핵무기 핵 시설 폐기 신고 의심 지역 사찰단 허용 검증 프로토콜 의미 관련 존재 말그 대한 대가 김 위원장 안보 보장 것 이 미국 종전선언 약속 북미 관계 정상 조치 수 상대국 수도 연락 사무소 개설 포함또한 정상회담 이 중요한 목표 합의 협상 대표 정기 신속 목표 추진 로드맵 수 정상회담 성공 간주 것 주장그 미국 국제 사회 관계 정상 북한 제재 고립 대가 이번 정상회담 김 위원장 핵 포기 것 여부 히 수 무엇 바람직한 일 것 공통 목표 관심 긴밀한 한미 동맹 토대 차 북미 정상회담 향후 대북 관계 가늠 수 선도 지표 수 것 말출처 대한민국 정책 브리핑',\n",
       " '문재인 대통령 월 일 시 분 분 동안 도널드 트럼프 미국 대통령 전화 통화 베트남 하노이 개최 차 북 미 정상 회담 주요 결과 평가 공유 한편 후속 대책 위한 미 간 공조 방안 심도 의견 교환문 대통령 트럼프 대통령 싱가포르 정상회담 한 김 위원장 한반도 핵 평화 정착 공동 목표 달성 장시간 심도 협의 데 평가 정상 차원 서로 입장 확인 구체 사항 협의한 후속 협의 성과 기대 말트럼프 대통령 김 위원장 회담 결과 문재인 대통령 공유 의견 회담 내용 설명문 대통령 지구 마지막 한반도 냉전 갈등 대립 시대 종식 평화 시대 역사 과업 달성 트럼프 대통령 지속 의지 결단 기대 우리 한미 간 긴밀한 공조하 필요한 역할 지원 것트럼프 대통령 이번 정상회담 합의 못한 데 아쉬움 표 한편 향후 북한 대화 타결 의지문 대통령 김정은 위원장 대화 결과 트럼프 대통령 등 적극 중재 역할 것 당부트럼프 대통령 향후 북한 핵 의지 실천 이행 히 공조문 대통령 시일 안 트럼프 대통령 심도 협의 계속 트럼프 대통령 이 동의 외교 경로 협의',\n",
       " '한미 연합 훈련 키리졸 브 연습 독수리 훈련 역사 속훈련 이름 년 년 만정경두 국방부 장관 패트릭 섀너핸 미국 국방부 장관 대행 일 전화 통화 훈련 종료 결정 때문올해 이름 연합 훈련 한 것국방부 일 양국 국방부 장관 통화 결정 발표',\n",
       " '키리졸브연습 한미 연합군 사령부 연합 사 작전 계획 등 적용 컴퓨터 시뮬레이션 진행 워게임연합방위태세 점검 북한 도발 전쟁 발생 때 이 수행 절차 중점 실시 연합 전구 급 지휘소 연습 한국 측 국방부 합참 육 해 공군 작전 사령부 국방부 직할 합동 부대 미 측 연합 사령부 주한 미군 사령부 태평양 사령부 등 참가연합 전시 증원 연습 연합 훈련 년 키리졸브당시 전시 작전 통제 전환 합의 기존 연합 훈련 기본 모델 수정 판단 일차 명칭 변경 검토한 데 것년 미 측 주장 주요한 결 뜻 키리졸브 연습시행당시 미 측 전쟁 승리 수 자신감 결의 표현 키리졸브 이름 작명년 시작 팀 스피릿 훈련 시초 년 년 시행 시기 년 년 간 키리졸브 시행 것작년 남북정상회담 북미정상회담 분위기 조성 키 절제 대응 진행북한 핵 미사일 실험 빈발 년 핵 추진 항공모함 칼빈슨호 등 전략 무기 참가한 가운데 공세 진행키리졸브 동맹 이름 지휘소 연습 훈련 시행 연도 명칭 앞 수예 이번 훈련 경우 동맹 것지난달 일 동맹 예비 단계 위기관리 연습 시행일 일 간 시행 훈련 변경 명칭 진행본 훈련 예년 대폭 미군 병력주한미군 참가 병력 규모 히주말 시행 일 종료 미국 전략 무기 참가키리졸 브 독수리 훈련 역사 속 북미 담판 결렬 종료 결정 종합 통신 일 미국 정부 당국자 인용 보도한 바 훈련 규모 연습 모의 훈련 시뮬레이션 대대 중대 급 규모 부대 참여한미 훈련 일정 훈련 시나리오 변화 안보 상황 부응 대폭 조정한 것부 반격 연습 등 축소 시행그간 연습 부 부 주 가량 시행올해 부 반격 연습 생략 주일 훈련 기간 작전 개념 예행 연습 개념 점검 쪽 가닥 것년 년 우리 합참 훈련 계획 수립 대항 군 운용 사후 검토 주도올해 전시 작전 통제 전환 검증 단계 최초 작전 운용 능력 평가 때문 올해 한국군 훈련 주도 것명칭 독수리 훈련 년 규모 후방 지역 방어 훈련 시작처음 독수리 한글 명칭 시행이후 년 연합 합동 작전 연합 특수 작전 개념 추가 해 독수리 훈련 영어 이름년 이후 정규 개념 적용 특전 부대 침투 타격 훈련 중요 시설 방호 훈련 병행 야외 기동 훈련 확대년 훈련 효율성 제고 전투력 향상 연습 통합 시행년 연습 연습 통합 시행최근 연합 기동 훈련 해상 전투 단 훈련 연합 상륙 훈련 연합 공격 편 대군 훈련 등 한미 연합 작전 후방 지역 방호 작전 능력 배양 훈련 발전이달 중순 대대 급 이하 규모 부대 참여 상시 연합 훈련훈련 명칭 훈련 부대 간년 월 실시 을지프리덤 가디언 명칭 것주목 부분 차 북미 정상회담 합의 결렬 한미 방침 훈련 종료 발표한 대목여기 김정은 국무 위원장 핵 탄도 미사일 실험 중단 유지 뜻 도널드 트럼프 대통령 점 감안 것북미 협상 가변 규모 한미 연합 훈련 중단 북한 핵 미사일 실험 중단 쌍 중단 구도 한미 쪽 경우 북한 강경한 대응 예상 만큼 상황 관리 측면 감안한 셈트럼프 요 수트럼프 대통령 지난달 일 김정은 위원장 정상회담 후 기자회견 한미 연합 군사 훈련 재개 생각 중단 상태 것 질문 군사 훈련 내 전 포기 때 억 달러 비용 초래폭격기 괌 내 처음 이거 시작 때 한 장군 폭격기 괌 옆 옆 시간 거리 폭격기 수백만 달러 폭탄 거 우리 훈련 수억 달러 사용 것 마음 공정 생각 말트럼프 대통령 작년 월 일 북미정상회담 후 기자회견 한미 연합 훈련 중단 시사 폭탄 발언그 우리 군사연습 중단 것 우리 비용 절감 것 그것 한미 연합 군사 훈련 도발 환경 아래 우리 완전한 거래 협상 연합 훈련 것 말발언 비용 연합 훈련 부정 견해 것트럼프 대통령 언급 앞 미군 전략 무기 대거 한반도 투입 훈련 사례 전망미국 올해 적용 방위비 분담금 협상 때 미국 태평양 사령부 연간 한반도 출동 전략 무기 전체 예산 월 일정액 우리나라 부담 관철결국 키 리졸브 독수리 훈련 작년 초 시작 한반도 정세 변화 흐름 속 역사 속한미 연합 방위 태세 일정한 희생 감수한 채 북 핵 폐기 협상 지원 장기 안보 이익 감안 이번 결정 대한 평가 진행 중 비핵화 평화 프로세스 결말 수 것현재 프로세스가 비핵 화 평화 협정 북미 수교 도달 경우 한미 용기 전략 결단 평가 전망반대 교착 역진 경우 북한 핵 미사일 위협 상황 한미 동맹 대비 태세 약화 지적 수',\n",
       " '일본 주요 언론 매체 일 베트남 하노이 2차 북미 정상회담 하노이 선언문 서명 등 구체 성과 못한 채 소식 긴급 뉴스 등 속보 경쟁일본 공영 방송 NHK 북미 정상 회담 합의 종료 직후 도널드 트럼프 대통령 하노이 현지 기자회견 내용 중계NHK 동시통역 사 투입한 중계 트럼프 대통령 마이크 폼페이오 국무 장관 브리핑 내용 통역 음성 자막 실시간 보도교도통신 이날 오후 시 분 회담 종료 소식 전한 지 분 만 시 분 글자체 \"합의 긴급 속보 뒤 트럼프 대통령 이후 기자회견 내용 한 줄 뉴스 타전교도 합의 실패 트럼프 대통령 회담 장 분위기 우호 영변 핵 시설 폐기 제재 완화 트럼프 대통령 말일본 일간지 중 최다 발행 부수 자랑 요미우리신문 인터넷판 헤드라인 뉴스 영역 속보 창 차 북미 회담 결렬 관련 소식 집중 배치요미우리 북한 제재 해제 요구 이견 이번 회담 합의 결렬 썼다마이니치신문 인터넷판 뉴스 뜻 호외 표시 핵 합의데 방점 보도 일본 3 대 일간지 아사히신문 트럼프 대통령 기자회견 내용 상단 속보 창 \"제재 완전 해제 제목 부각 아사히 예상 외 전개 이날 오후 시 트럼프 대통령 기자회견 전후 상황 시간대 정리 우익 성향 산케이 신문 홈페이지 위쪽 기자회견 트럼프 대통령 사진 배치한 뒤 북한 완전한 제재해제 요구 트럼프 대통령 소개',\n",
       " '제2차 북미 정상 회담 합의 결렬 북한 일 이 언급 채 회담 긍정 측면대외 미국 대화 계속 의지 한편 안 회담 실패 명분 수 김정은 국무 위원장 핵 노선 주민 결속 의미 풀이노동 당 기관지 노동 신문 이날 전체 면 중 면 김정은 국무 위원장 도널드 트럼프 미국 대통령 간 정상회담 사진 장 베트남 하노이 전날 진행 회담 히 보도전날 면 긍정 분위기 중심 회담 사진 장 편집 이날 일 듯 개 면 장 사진 보도한 것이날 신문 1면 전날 북미 단독정상회담 사진 장 정상 악수 인사 장면 원탁 회담 장면 시종 미소 모습면 김 위원장 트럼프 대통령 단독회담 직후 회담 장인 하노이 메트로 폴 호텔 분 간 진행한 정원 산책 모습 진행 확대회담 등 사진 장김 위원장 도널드 트럼프 대통령 산책 중 손동작 적극 대화 모습확대 회담 북측 김영철 노동당 부위원장 리용호 외무상 등 명 미국 측 마이크 폼페이오 국무 장관 존 볼턴 백악관 국가 안보 회의 보좌관 믹 멀베 백악관 비서실장 대행 등 명 배석한 가운데 측 참석자 테이블 손 표정 회의김 위원장 치아 상기한 얼굴 모습 눈노동신문 김 위원장 트럼프 대통령 이번 상봉 회담 성과 적극 노력 데 사의 표 상봉 약속이번 회담 조 미 관계 나라 인민 이익 발전 조선 반도 지역 세계 평화 안전 이바지 의미 계기 평가조선중앙통신 조선중앙방송 내용 보도보도 김 위원장 트럼프 대통령 예정 오찬 취소 회의 결국 합의문 서명 회담 결렬 현실 온도 차북한 회담 결렬 후 리용호 외무상 최선희 부상 새벽 기자회견 김 위원장 조미 거래 의욕 느낌 \"미국 측 이번 것 천재일우 기회 것 등 평가 긍정 평가 일색 북한 보도 이질감이 관련 북한 미국 대화 가능 앞 협상 계속 뜻 대외 것 분석',\n",
       " '도널드 트럼프 미국 대통령 연두교서 제2차 북미 정상회담 날짜 확정 세계 이목 월 말 베트남BBC 일 현지 시간 일 진행 제2차 북미 정상회담 주요 관전 포인트화려한 행사 실무협상 중요 지난해 월 제1차 북미 정상회담 미국 정상 북한 정상 역사 처음 공식 회담 점 상징 의미교착 끝 진행 제2차 북미 정상회담 상징 행사 실제 결과 것 공통 시각BBC 이 관련 트럼프 대통령 김정은 북한 국무 위원장 대화 방식 지적 그 핵 대치 개인 지적매체 그 거래 따뜻한 말 서한 교환 강조BBC 김 위원장 직감 의존 거 유명한 그 펜팔 친구 트럼프 대통령 합의 유리 것 워싱턴 우려 김 위원장 그 업무 분석 김 위원장 주도 이번 회담 식 수 우려 시사제2차 정상회담 식 회담 실질 결과 정상회담 세부 사항 사전 실무협상 중요스티븐 비건 미 국무부 대북 정책 특별대표 평양 협상 진행 중 만큼 정상회담 의 합의 틀 세부 마련 주목북미 핵 표현 의미 정확한 일치 트럼프 대통령 김정은 위원장 지난해 월 제1차 북미 정상회담 당시 한반도 완전한 비핵 합의 문구정상회담 8 개월 현재 핵 의미 절차 대한 해석북한 의미 핵 이 일치 미지수BBC 북한 핵 미국 한반도 평양 위협 수 능력 철회 쌍무 단계 것 분석점 트럼프 대통령 최근 주한미군 발언그 일 주한 미군 철수 문제 \"논의한 누 군 곳 한국 주둔 것 지적한 바BBC 김 위원장 비핵화 대한 서면 정의 공식 약속한 적 핵 서면 정의 핵 도달 대한 상세 로드맵 동의 김 위원장 압박 것 전문가 말북한 실질 핵 조치 북한 제1차 정상회담 해 월 풍계 리 핵실험 장 파괴 조치 취한 바미사일 발사 등 도발 행위 년 중단 상황김정은 위원장 월 신년사 핵무기 실험 제조 전파 중단 선언실질 핵 조치 북한 보유한 핵무기 제거 폐기 필수제2차 북미 정상회담 성패 최종 검증 가능한 핵비건 국무부 특별대표 이 관련 스탠퍼드 연설 김 위원장 지난해 월 마이크 폼페이오 국무 장관 북한 플루토늄 우라늄 농축 시설 해체 파괴 것 약속 말실질 핵 조치 가능 언급한 것문제 트럼프 대통령 명확한 핵 계획 즉석 임시 합의 수 것 지적즉흥 트럼프 대통령 성향 실질 핵 조치 이벤트 합의 수 것핵 보유국 인정 일 각서 현실 시각 의견 일각 북한 핵무기 포기 의향 간주 현실 시각 협상 진행 의견이 관련 코츠 미 국가 정보 국 국장 최근 미 상원 위원회 북한 궁극 핵무기 정권 생존 중요 지적BBC 전문가 김 위원장 북한 핵 보유국 인정 필요한 외교 분위기 조성 데 노력 지적매체 전직 국방부 관계자 인용 무기 제거 무기 컨트롤 대한 대화 추구 것 더 것',\n",
       " '김정은 북한 국무 위원장 베트남 하노이 2차 북미 정상회담 참석 일 오전 베트남 입국김 위원장 전용 열차 이날 오전 시 분 현지 시간 한국 시간 오전 시 분 중국 접경 지역 베트남 랑선성 동당역 진입 분 플랫폼 한국 시간 일 오후 시 분 평양역 출발한 김 위원장 전용 열차 천 거리 시간 분 동안 베트남 입성김 위원장 오전 시 분 장 기색 열차 하차평양역 출발 당시 색 모직 코트 채 인민 복 차림 앞머리 포마드 이용 뒤의전 경호 총괄 김창선 국무위원회 부장 열차 위치 조율 김여정 당 선전 선동 부 부 부장 주변 상황 모습 화면 포착김 위원장 미소 채 반 베트남 공산당 선전 담당 정치국 마이 엔 중 총리실 장관 대화 뒤 뒤 도열 베트남 정부 관계자 악수목소리 입 말 것뒤 수행 단 김영철 리수용 김평해 오수용 노동당 부위원장 리용호 외무상 노광 철 인민 무력 상 최선희 외무성 부 상 등 열차김 위원장 오전 시 분 동당 역 앞 대기 중 전용 차 국도 호 선 하노이 구간 시간 분 이동 것 예상베트남 정부 자국 공식 친선 방문 김 위원장 군 장대 사열 준비 역 주변 양국 국기 게양 바닥 레드카펫베트남 주민 한 손 베트남 국기 한 손 인공기 손 채 김 위원장 환영',\n",
       " '김정은 북한 국무 위원장 이번 2차 북미 정상회담 결과 북한 목표 경제 건설 총력 집중 노선 명 운 수 점 의미집권 후 최 장 공백 불안 위험 감수 시간 열차 행 군 강행한 이유 여기김 위원장 내년 노동당 창건 주년 국가 경제 발전 개년 전략 마지막 해 만큼 올해 안 대북 제재 완화 경제 성장 토대 마련 것 무엇지난해 월 싱가포르 1차 북미 정상회담 이후 개월 만 지도자 개월 과정핵 협상 고비 때 김 위원장 통 결단 핵 향한 의지 역할앤드루 김 중앙정보국 코리아 미션 센터 장 공개 나 아이 평생 핵 거 김 위원장 발언북한 국내 정치 측면 2차 북미 정상회담 김 위원장 중요한 의미제재 완화 관련한 실질 성과 김 위원장 향후 경제 성장 박차 것핵 개방 반대 내부 세력 본인 선택 것 증명 설득 경제 성과 때문북한 지난해 월 핵 경제 병진 노선 경제 건설 총력 집중 노선 전환 성과 상황 한국은행 최근 년 북한 경제 성장 추정년 이후 폭 하락한 것김 위원장 지난해 월 정의용 청와대 국가안보실 장 등 특사 단 자리 나 판단 판단 수 여건 당부김 위원장 2차 북미 정상회담 후 문재인 대통령 약속한 서울 답 방 실행 것이 계기 철도 도로 사회 간접 자본 등 남북 경제 협력 사업 속도 북한 경제 숨통 터 수올해 초 신년사 조건 개성공단 금강산 관광 재개 언급2차 북미 정상회담 핵 협상 진전 김 위원장 천명한 경제 총력 노선 내부 동력 여지김 위원장 신년사 미국 제재 압박 수 길 모색 수 언급한 북미 관계 가능 배제 수']"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from collections import defaultdict\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "sp_matrix = vectorizer.fit_transform(corpus)\n",
    "\n",
    "word2id = defaultdict(lambda : 0)\n",
    "for idx, feature in enumerate(vectorizer.get_feature_names()):\n",
    "    word2id[feature] = idx\n",
    "\n",
    "mylist = []\n",
    "for i, sent in enumerate(corpus):\n",
    "#     print('====== document[%d] ======' % i)\n",
    "    mylist.append([(token, sp_matrix[i, word2id[token]]) for token in sent.split()])\n",
    "#     print( [ (token, sp_matrix[i, word2id[token]]) for token in sent.split() ] )\n",
    "    if i % 10000 == 0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "for m in mylist:\n",
    "    words = []\n",
    "    values = []\n",
    "    for noun in m:\n",
    "        words.append(noun[0])\n",
    "        values.append(noun[1])\n",
    "    doc = pd.DataFrame({\"word\":words, \"value\":values})\n",
    "    doc = doc.drop_duplicates(['word'])\n",
    "    doc = doc.sort_values(by = 'value', ascending = False)\n",
    "    docs.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = []\n",
    "for doc in docs:\n",
    "    df2 = pd.DataFrame(doc)\n",
    "    topic = []\n",
    "    for i in range(len(df2)):\n",
    "        topic.append(df2.iloc[i]['word'])\n",
    "        if(i == 9):\n",
    "            break\n",
    "    topics.append(', '.join(topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_topics = topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['북한, 정상회담, 회담, 한반도, 비핵화, 북미, 합의, 미국, 협의, 포괄',\n",
       " '정상회담, 북미, 미국, 합의, 한국, 목표, 관련, 북한, 관계, 성공',\n",
       " '대통령, 트럼프, 협의, 회담, 결과, 심도, 위원장, 한편, 향후, 평가',\n",
       " '훈련, 국방부, 장관, 결정, 통화, 이름, 연합, 한미, 미국, 양국',\n",
       " '훈련, 연합, 연습, 한미, 작전, 중단, 명칭, 사령부, 규모, 시행',\n",
       " '트럼프, 대통령, 기자회견, 회담, 뉴스, 합의, 내용, 속보, 북미, 하노이',\n",
       " '회담, 위원장, 대통령, 사진, 미국, 트럼프, 대화, 긍정, 국무, 북한',\n",
       " '위원장, 정상회담, 북한, 트럼프, 대통령, 북미, 합의, 조치, 대한, 핵무기',\n",
       " '위원장, 베트남, 시간, 오전, 열차, 전용, 정부, 국기, 부장, 한국',\n",
       " '경제, 위원장, 북미, 정상회담, 북한, 노선, 총력, 성장, 2차, 성과']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "article_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['회담, 위원장, 영변, 조건, 결렬, 하노이, 김정은, 대통령, 정상, 미국',\n",
       " '진화, 산불, 피해, 인근, 출동, 오후, 강원도, 토성면, 원암리, 강풍',\n",
       " '구조, 수색, 헝가리인, 크루즈, 바이킹, 승무원, 헝가리, 정부, 외교부, 강경화',\n",
       " '회담, 대통령, 트럼프, 정상, 중요, 실무, 도널드, 미국, 김정은, 합의']"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "oasis_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------\n[0.2 0.1 0.3 0.1 0.  0.3 0.4 0.2 0.1 0.1]\n[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n[0.  0.  0.  0.  0.  0.  0.  0.  0.1 0. ]\n[0.3 0.2 0.3 0.1 0.  0.4 0.4 0.3 0.  0. ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#코사인 유사도 threshold\n",
    "cosine_similarity_threshold = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "tfidf = CountVectorizer()\n",
    "\n",
    "TP = [0, 0, 0, 0] # our's O oasis O\n",
    "FP = [0, 0, 0, 0] # our's O oasis X\n",
    "FN = [0, 0, 0, 0] # our's X oasis O\n",
    "\n",
    "for topic in article_topics:\n",
    "    topic_list = []\n",
    "    topic_list.append(topic)\n",
    "    topic_list.extend(oasis_topic)\n",
    "    \n",
    "    vec = tfidf.fit_transform(topic_list)\n",
    "    \n",
    "    similarity = cosine_similarity(vec[0], vec)[0][1:]\n",
    "    for i in range(4):\n",
    "        check = False\n",
    "        for sim in similarity:\n",
    "            if sim >= cosine_similarity_threshold[i]:\n",
    "                check = True\n",
    "                break\n",
    "        if check:\n",
    "            TP[i] += 1\n",
    "        else:\n",
    "            FP[i] += 1\n",
    "    #print(similarity)\n",
    "\n",
    "print('----------------')            \n",
    "for topic in oasis_topic:\n",
    "    topic_list = []\n",
    "    topic_list.append(topic)\n",
    "    topic_list.extend(article_topics)\n",
    "    \n",
    "    vec = tfidf.fit_transform(topic_list)\n",
    "    \n",
    "    similarity = cosine_similarity(vec[0], vec)[0][1:]\n",
    "    print(similarity)\n",
    "    for i in range(4):\n",
    "        check = False\n",
    "        for sim in similarity:\n",
    "            if sim >= cosine_similarity_threshold[i]:\n",
    "                check = True\n",
    "                break\n",
    "        if not check:\n",
    "            FN[i] += 1\n",
    "    \n",
    "\n",
    "#print(TP, FP, FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.2 0.1 0.3 0.1 0.  0.3 0.4 0.2 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['북한, 정상회담, 미국, 위원장, 대통령, 도널드트럼프, 회담, 북미, 김정은, 협상, 북미정상, 한반도, 대화, 하노이, 중국, 정상, 평화, 비핵화, 베트남, 남북',\n",
       " '산불, 대통령, 강원도, 피해, 국회, 지역, 재난, 정부, 발생, 대표, 한국당, 장관, 강원, 지원, 국민, 고성, 대응, 청와대, 상황, 화재',\n",
       " '대통령, 북한, 정상회담, 도널드트럼프, 위원장, 미국, 대화, 한반도, 평화, 회담, 남북, 김정은, 북미, 정상, 비핵화, 남북미, 협상, 북미정상, 한국, 하노이',\n",
       " '헝가리, 사고, 유람선, 침몰, 다뉴브강, 한국인, 부다페스트, 수색, 시신, 실종자, 인양, 구조, 현지, 확인, 현장, 정부, 한국, 작업, 수습, 선체']"
      ]
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n",
    "\n",
    "#코사인 유사도 threshold\n",
    "#cosine_similarity_threshold = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "tfidf = CountVectorizer()\n",
    "\n",
    "# TP = [0, 0, 0, 0] # our's O oasis O\n",
    "# FP = [0, 0, 0, 0] # our's O oasis X\n",
    "# FN = [0, 0, 0, 0] # our's X oasis O\n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "\n",
    "df1=pd.read_csv('../PostProcess/Data/2019_cluster_topics3.csv','r',encoding='utf-8-sig')\n",
    "df2=pd.read_csv('../PostProcess/Data/2019_big_topics.csv','r',encoding='cp949')\n",
    "\n",
    "article_topics=[]\n",
    "for topic in df1['topics']:\n",
    "    arr=re.sub(\"[\\[,'\\]]\", '',topic).split(' ')\n",
    "    arr=\", \".join(arr)\n",
    "    article_topics.append(arr)\n",
    "\n",
    "big_topics=[]\n",
    "for topic in df2['topics']:\n",
    "    arr=re.sub(\"[\\[,'\\]]\", '',topic).split(' ')\n",
    "    arr=\", \".join(arr)\n",
    "    big_topics.append(arr)\n",
    "\n",
    "big_topics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0.5769328761339176, 0.02910849362175736, 0.5101490193104814, 0.0]\n",
      "[0.05629715757507137, 0.027395330814104696, 0.08683346737229902, 0.05629715757507137]\n",
      "[0.08201057813079436, 0.0532538373370539, 0.08201057813079436, 0.02595291901635106]\n",
      "[0.028212976524438108, 0.0, 0.028212976524438108, 0.028212976524438108]\n",
      "[0.02910849362175736, 0.05992996822422367, 0.02910849362175736, 0.0]\n",
      "[0.0, 0.028212976524438105, 0.0, 0.05802845068119371]\n",
      "[0.028212976524438108, 0.05802845068119371, 0.028212976524438108, 0.028212976524438105]\n",
      "[0.0, 0.026644887802214676, 0.0, 0.026644887802214676]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.028212976524438108, 0.0, 0.0]\n",
      "[0.0, 0.026644887802214676, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.18375568986292978, 0.054712118539283594, 0.18375568986292978, 0.026644887802214676]\n",
      "[0.054712118539283594, 0.026644887802214676, 0.054712118539283594, 0.0]\n",
      "[0.32600302866471614, 0.028212976524438108, 0.32600302866471614, 0.0]\n",
      "[0.0, 0.08431875054119921, 0.0, 0.026644887802214676]\n",
      "[0.08431875054119921, 0.054712118539283594, 0.08431875054119921, 0.0]\n",
      "[0.0, 0.027395330814104696, 0.0, 0.027395330814104696]\n",
      "[0.0, 0.08431875054119922, 0.0, 0.0]\n",
      "[0.0, 0.027395330814104696, 0.027395330814104696, 0.05629715757507137]\n",
      "[0.054712118539283594, 0.0, 0.026644887802214676, 0.026644887802214676]\n",
      "[0.0532538373370539, 0.02595291901635106, 0.02595291901635106, 0.02595291901635106]\n",
      "[0.0, 0.0532538373370539, 0.0, 0.02595291901635106]\n",
      "[0.0, 0.0, 0.0, 0.026644887802214676]\n",
      "[0.18976728433844905, 0.027395330814104692, 0.15339846575647695, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.02595291901635106, 0.14438355527738672, 0.02595291901635106, 0.0]\n",
      "[0.0, 0.054712118539283594, 0.0, 0.026644887802214676]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.02595291901635106, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.027395330814104696, 0.05629715757507137, 0.0, 0.027395330814104696]\n",
      "[0.0, 0.05802845068119371, 0.0, 0.0]\n",
      "[0.08431875054119921, 0.0, 0.08431875054119918, 0.0]\n",
      "[0.0, 0.026644887802214676, 0.0, 0.0]\n",
      "[0.026644887802214676, 0.0, 0.026644887802214676, 0.0]\n",
      "[0.05629715757507137, 0.05629715757507137, 0.05629715757507137, 0.0]\n",
      "[0.05802845068119372, 0.0, 0.05802845068119372, 0.0]\n",
      "[0.027395330814104696, 0.05629715757507137, 0.027395330814104696, 0.0]\n",
      "[0.027395330814104692, 0.05629715757507137, 0.027395330814104692, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.0, 0.0, 0.5883635900492962]\n",
      "[0.0, 0.0, 0.0, 0.028212976524438108]\n",
      "[0.0, 0.15339846575647686, 0.0, 0.027395330814104692]\n",
      "[0.0, 0.054712118539283594, 0.0, 0.026644887802214676]\n",
      "[0.0, 0.0, 0.0, 0.0]\n",
      "----------------\n",
      "[0.5769328761339176, 0.05629715757507137, 0.08201057813079436, 0.028212976524438108, 0.02910849362175736, 0.0, 0.028212976524438108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18375568986292978, 0.054712118539283594, 0.32600302866471614, 0.0, 0.08431875054119921, 0.0, 0.0, 0.0, 0.054712118539283594, 0.0532538373370539, 0.0, 0.0, 0.18976728433844905, 0.0, 0.02595291901635106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027395330814104696, 0.0, 0.08431875054119921, 0.0, 0.026644887802214676, 0.05629715757507137, 0.05802845068119372, 0.027395330814104696, 0.027395330814104692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.02910849362175736, 0.027395330814104696, 0.0532538373370539, 0.0, 0.05992996822422367, 0.028212976524438105, 0.05802845068119371, 0.026644887802214676, 0.0, 0.0, 0.028212976524438108, 0.026644887802214676, 0.0, 0.054712118539283594, 0.026644887802214676, 0.028212976524438108, 0.08431875054119921, 0.054712118539283594, 0.027395330814104696, 0.08431875054119922, 0.027395330814104696, 0.0, 0.02595291901635106, 0.0532538373370539, 0.0, 0.027395330814104692, 0.0, 0.14438355527738672, 0.054712118539283594, 0.0, 0.0, 0.02595291901635106, 0.0, 0.0, 0.0, 0.05629715757507137, 0.05802845068119371, 0.0, 0.026644887802214676, 0.0, 0.05629715757507137, 0.0, 0.05629715757507137, 0.05629715757507137, 0.0, 0.0, 0.0, 0.1533984657564769, 0.054712118539283594, 0.0]\n",
      "[0.5101490193104814, 0.08683346737229902, 0.08201057813079436, 0.028212976524438108, 0.02910849362175736, 0.0, 0.028212976524438108, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.18375568986292973, 0.054712118539283594, 0.32600302866471614, 0.0, 0.08431875054119921, 0.0, 0.0, 0.027395330814104696, 0.026644887802214676, 0.02595291901635106, 0.0, 0.0, 0.1533984657564769, 0.0, 0.02595291901635106, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.08431875054119918, 0.0, 0.026644887802214676, 0.05629715757507137, 0.05802845068119372, 0.027395330814104696, 0.027395330814104692, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "[0.0, 0.05629715757507137, 0.02595291901635106, 0.028212976524438108, 0.0, 0.05802845068119371, 0.028212976524438105, 0.026644887802214676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.026644887802214676, 0.0, 0.0, 0.026644887802214676, 0.0, 0.027395330814104696, 0.0, 0.05629715757507137, 0.026644887802214676, 0.02595291901635106, 0.02595291901635106, 0.026644887802214676, 0.0, 0.0, 0.0, 0.026644887802214676, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.027395330814104696, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5883635900492962, 0.028212976524438108, 0.027395330814104692, 0.026644887802214676, 0.0]\n",
      "2 48 1\n",
      "precision:0.04,recall:0.6666666666666666,F_score:0.07547169811320754\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "TP=0\n",
    "FP=0\n",
    "FN=0\n",
    "\n",
    "def cos_similarity(v1, v2):\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    l2_norm = (np.sqrt(sum(np.square(v1))) * np.sqrt(sum(np.square(v2))))\n",
    "    similarity = dot_product / l2_norm     \n",
    "    \n",
    "    return similarity\n",
    "\n",
    "\n",
    "for topic in article_topics:\n",
    "    similarity=[]\n",
    "\n",
    "    for btopic in big_topics:\n",
    "        topic_list = []\n",
    "        topic_list.append(topic)\n",
    "        topic_list.append(btopic)\n",
    "\n",
    "        tfidf_vect_simple = TfidfVectorizer(min_df=1)\n",
    "        feature_vect_simple = tfidf_vect_simple.fit_transform(topic_list)\n",
    "\n",
    "        feature_vect_dense = feature_vect_simple.todense()\n",
    "\n",
    "        vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "        vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "\n",
    "        similarity_simple = cos_similarity(vect1, vect2)\n",
    "        similarity.append(similarity_simple)\n",
    "    #vec = tfidf.fit_transform(topic_list)\n",
    "    \n",
    "    #similarity = cosine_similarity(vec[0], vec)[0][1:]\n",
    "    print(similarity)\n",
    "    check=False\n",
    "    for sim in similarity:\n",
    "        if sim >= 0.5:\n",
    "            check=True\n",
    "            break\n",
    "    if check:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FP+= 1\n",
    "    #print(similarity)\n",
    "\n",
    "print('----------------')            \n",
    "for topic in big_topics:\n",
    "\n",
    "    similarity=[]\n",
    "    for itopic in article_topics:\n",
    "        topic_list = []\n",
    "        topic_list.append(topic)\n",
    "        topic_list.append(itopic)\n",
    "\n",
    "        tfidf_vect_simple = TfidfVectorizer(min_df=1)\n",
    "        feature_vect_simple = tfidf_vect_simple.fit_transform(topic_list)\n",
    "\n",
    "        feature_vect_dense = feature_vect_simple.todense()\n",
    "\n",
    "        vect1 = np.array(feature_vect_dense[0]).reshape(-1,)\n",
    "        vect2 = np.array(feature_vect_dense[1]).reshape(-1,)\n",
    "\n",
    "        similarity_simple = cos_similarity(vect1, vect2)\n",
    "        similarity.append(similarity_simple)\n",
    "        \n",
    "    #vec = tfidf.fit_transform(topic_list)\n",
    "    \n",
    "    #similarity = cosine_similarity(vec[0], vec)[0][1:]\n",
    "    print(similarity)\n",
    "    check=False\n",
    "    for sim in similarity:\n",
    "        if sim >= 0.5:\n",
    "            check=True\n",
    "            break\n",
    "    if not check:\n",
    "        FN+= 1\n",
    "    \n",
    "\n",
    "print(TP, FP, FN)\n",
    "\n",
    "precision=(TP)/(TP+FP)\n",
    "recall=(TP)/(TP+FN)\n",
    "\n",
    "F_score=2*((precision*recall)/(precision+recall))\n",
    "\n",
    "print(\"precision:{},recall:{},F_score:{}\".format(precision,recall,F_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------\n2 48 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "#코사인 유사도 threshold\n",
    "\n",
    "\n",
    "tfidf = CountVectorizer()\n",
    "\n",
    "TP = 0 # our's O oasis O\n",
    "FP = 0 # our's O oasis X\n",
    "FN = 0 # our's X oasis O\n",
    "\n",
    "for topic in article_topics:\n",
    "    topic_list = []\n",
    "    topic_list.append(topic)\n",
    "    topic_list.extend(big_topics)\n",
    "    \n",
    "    vec = tfidf.fit_transform(topic_list)\n",
    "    \n",
    "    similarity = cosine_similarity(vec[0], vec)[0][1:]\n",
    "\n",
    "    check = False\n",
    "    for sim in similarity:\n",
    "        if sim >= 0.5:\n",
    "            check = True\n",
    "            break\n",
    "    if check:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FP += 1\n",
    "    #print(similarity)\n",
    "\n",
    "print('----------------')            \n",
    "for topic in big_topics:\n",
    "    topic_list = []\n",
    "    topic_list.append(topic)\n",
    "    topic_list.extend(article_topics)\n",
    "    \n",
    "    vec = tfidf.fit_transform(topic_list)\n",
    "    \n",
    "    similarity = cosine_similarity(vec[0], vec)[0][1:]\n",
    "    #print(similarity)\n",
    "\n",
    "    check = False\n",
    "    for sim in similarity:\n",
    "        if sim >= 0.5:\n",
    "            check = True\n",
    "            break\n",
    "    if not check:\n",
    "        FN += 1\n",
    "    \n",
    "\n",
    "print(TP, FP, FN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python385jvsc74a57bd000c48d4780e7fa7f4b695bd71b2ac9722a525fe5d5880a11d633cd1f8478baa2",
   "display_name": "Python 3.8.5 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "00c48d4780e7fa7f4b695bd71b2ac9722a525fe5d5880a11d633cd1f8478baa2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}